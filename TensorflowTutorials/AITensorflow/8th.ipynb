{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8차시: 텐서플로우 2.x 활용 Speech Recognition\n",
    "\n",
    "## AI 맛보기 8주차: 2020. 08. 25. 20:00 ~ 22:00 (120분)\n",
    "1. 도구 불러오기 및 버전 확인\n",
    "1. 학습 데이터 다운로드: \n",
    "1. 학습 데이터 살펴보기: 차원, 미리보기\n",
    "1. 학습 데이터 전처리 (정규화)\n",
    "1. 학습 모델 준비: Deep CNN\n",
    "1. 학습\n",
    "1. 학습 결과 테스트\n",
    "1. 확률 모델\n",
    "1. 예측\n",
    "1. Convolution Neural Network\n",
    "\n",
    "#### 참고자료\n",
    "- [파이썬 3 표준 문서](https://docs.python.org/3/index.html)\n",
    "- [텐서플로우 CNN](https://www.tensorflow.org/tutorials/images/cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 도구 불러오기 및 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 준비\n",
    "import os\n",
    "# import shutil\n",
    "# import random\n",
    "# import math\n",
    "\n",
    "import tensorflow as tf # 텐서플로우\n",
    "import tensorflow_io as tfio\n",
    "import matplotlib.pyplot as plt # 시각화 도구\n",
    "%matplotlib inline\n",
    "# import matplotlib.font_manager as fm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Tensorflow 버전을 확인합니다: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 학습 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r data_speech_commands\n",
    "!mkdir data_speech_commands\n",
    "!tar --directory data_speech_commands -xvf data_speech_commands_v0.02.tar.gz &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r data_speech_commands/_background_noise_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = './data_speech_commands'\n",
    "\n",
    "files = list()\n",
    "labels = list()\n",
    "lab = list()\n",
    "for l1 in os.scandir(path_root):\n",
    "    if l1.is_file():\n",
    "        continue\n",
    "    label = os.path.basename(l1.path)\n",
    "    if label not in lab:\n",
    "        lab.append(label)\n",
    "    label = lab.index(label)\n",
    "    for l2 in os.scandir(l1.path):\n",
    "        files.append(l2.path)\n",
    "        labels.append(label)\n",
    "dataset_root = tf.data.Dataset.from_tensor_slices((files, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(p.numpy().decode('utf-8'))\n",
    "display(l.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = tfio.audio.AudioIOTensor(p)\n",
    "print(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tensor = tf.squeeze(audio.to_tensor(), axis=[-1])\n",
    "print(audio_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.pad(audio_tensor, (0, 16000-len(audio_tensor[:16000])), 'constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.pad(audio_tensor[:15998], (0, 16000-len(audio_tensor[:15998])), 'constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tensor[15995:15998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio_tensor.numpy(), rate=audio.rate.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.cast(audio_tensor, tf.float32) / 2**16\n",
    "plt.figure()\n",
    "plt.plot(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to spectrogram\n",
    "spectrogram = tfio.experimental.audio.spectrogram(\n",
    "    tensor, nfft=512, window=512, stride=256)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(tf.math.log(spectrogram).numpy())\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(tf.math.log(spectrogram), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(spectrogram.numpy(), cmap='gray')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tensor[:15000].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Image.fromarray(spectrogram.numpy()*256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = i.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(i).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tensor[:16000].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(path, label):\n",
    "    audio = tfio.audio.AudioIOTensor(path, dtype='int16')\n",
    "    audio_tensor = tf.squeeze(audio.to_tensor(), axis=[-1])\n",
    "    print(audio_tensor[:16000].shape)\n",
    "    paddings = (16000-audio_tensor[:16000].shape[0])\n",
    "    \n",
    "    audio_tensor = tf.pad(audio_tensor[:16000], paddings,\n",
    "                          'constant', constant_values=0)\n",
    "    tensor = tf.cast(audio_tensor, tf.float32) / 2**16\n",
    "    spectrogram = tfio.experimental.audio.spectrogram(\n",
    "                          tensor, nfft=512, window=512, stride=256)\n",
    "    spectrogram_log = tf.expand_dims(tf.math.log(spectrogram), -1)\n",
    "    return spectrogram_log, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_root.map(load_audio).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('모델 생성')\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(tf.math.log(spectrogram).shape) + (1,)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('모델 컴파일')\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = model.fit(dataset,\n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 학습 결과 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "fig1 = plt.figure(figsize=(6, 10))\n",
    "ax = fig1.add_subplot(2, 1, 1)\n",
    "ax.plot(epochs, loss, 'bo', label='Training loss')\n",
    "ax.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "ax.set_ylim((0, math.ceil(max(max(loss), max(val_loss)))))\n",
    "ax.set_title('Training and validation loss', fontsize=12)\n",
    "ax.set_xlabel('Epochs', fontsize=10)\n",
    "ax.set_ylabel('Loss', fontsize=10)\n",
    "ax.legend()\n",
    "\n",
    "ax = fig1.add_subplot(2, 1, 2)\n",
    "ax.plot(epochs, acc, 'bo', label='Training acc')\n",
    "ax.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "ax.set_ylim((0, math.ceil(max(max(acc), max(val_acc)))))\n",
    "ax.set_title('Training and validation accuracy', fontsize=12)\n",
    "ax.set_xlabel('Epochs', fontsize=10)\n",
    "ax.set_ylabel('Accuracy', fontsize=10)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(test_images)}개 이미지로 테스트합니다.')\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print()\n",
    "print(f'테스트 이미지 정확도: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 확률 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('확률 모델')\n",
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "probability_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각 테스트이미지별 레이블 확률 계산')\n",
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "print(f'예측 레이블은 확률 중 최대 확률을 선택합니다.')\n",
    "print(f'Test image {idx} prediction: \\n{predictions[idx]}')\n",
    "print(f'Maximum probability label: {np.argmax(predictions[idx])}')\n",
    "print(f'Actual label: {test_labels[idx][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5 = plt.figure(figsize=(6, 6))\n",
    "ax = fig5.add_subplot()\n",
    "axm = ax.imshow(test_images[idx])\n",
    "fig5.suptitle(f'Test Image [{idx}]', fontsize=20)\n",
    "ax.set_title(f'Label: {class_names[test_labels[idx][0]]}', fontsize=16)\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 함수 정의\n",
    "def draw_image(ax, prob, image, true_label):\n",
    "    ax.grid(False)\n",
    "    axm = ax.imshow(image)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    predicted_label = np.argmax(prob)\n",
    "    if true_label == predicted_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    predicted_name = class_names[predicted_label]\n",
    "    true_name = class_names[true_label]\n",
    "    label = f'{predicted_name} {np.max(prob)*100:3.0f}% ({true_name})'\n",
    "    ax.set_title(f'{label}', color=color)\n",
    "    \n",
    "def draw_bar(ax, prob, true_label):\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks(range(10))\n",
    "    ax.set_yticks(np.arange(0, 1.2, 0.2))\n",
    "    bar = ax.bar(range(10), prob, color='gray')\n",
    "    ax.set_ylim((0, 1))\n",
    "    predicted_label = np.argmax(prob)\n",
    "    bar[predicted_label].set_color('red')\n",
    "    bar[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_images)):\n",
    "    if test_labels[i][0] == np.argmax(predictions[i]):\n",
    "        break\n",
    "fig6 = plt.figure(figsize=(6, 3))\n",
    "ax = fig6.add_subplot(1, 2, 1)\n",
    "draw_image(ax, predictions[i], test_images[i], test_labels[i][0])\n",
    "ax = fig6.add_subplot(1, 2, 2)\n",
    "draw_bar(ax, predictions[i], test_labels[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_images)):\n",
    "    if test_labels[i] != np.argmax(predictions[i]):\n",
    "        break\n",
    "fig7 = plt.figure(figsize=(6, 3))\n",
    "ax = fig7.add_subplot(1, 2, 1)\n",
    "draw_image(ax, predictions[i], test_images[i], test_labels[i][0])\n",
    "ax = fig7.add_subplot(1, 2, 2)\n",
    "draw_bar(ax, predictions[i], test_labels[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 5000\n",
    "rows = 1 * 5\n",
    "cols = 2 * 3\n",
    "fig8 = plt.figure(figsize=(2.5*cols, 2.5*rows))\n",
    "fig8.set_facecolor('white')\n",
    "for i in range(0, rows*cols, 2):\n",
    "    ax = fig8.add_subplot(rows, cols, i+1)\n",
    "    draw_image(ax, predictions[base+i], test_images[base+i], test_labels[base+i][0])\n",
    "    ax = fig8.add_subplot(rows, cols, i+2)\n",
    "    draw_bar(ax, predictions[base+i], test_labels[base+i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [layer.output for layer in model.layers[:-3]]\n",
    "intermediate_model = tf.keras.models.Model(inputs=model.input,\n",
    "                                           outputs=outputs)\n",
    "intermediate_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 1\n",
    "model_idx = 4\n",
    "intermediate_output = intermediate_model.predict(tf.expand_dims(test_images[image_idx], 0))\n",
    "data = intermediate_output[model_idx]\n",
    "\n",
    "fig9 = plt.figure(figsize=(3, 3))\n",
    "fig9.set_facecolor('white')\n",
    "ax = fig9.add_subplot()\n",
    "ax.imshow(train_images[image_idx])\n",
    "ax.grid(False)\n",
    "\n",
    "fig10 = plt.figure(figsize=(16, math.ceil(data.shape[-1]/16)))\n",
    "fig10.set_facecolor('white')\n",
    "for i in range(0, data.shape[-1]):\n",
    "    ax = fig10.add_subplot(math.ceil(data.shape[-1]/16), 16, i+1)\n",
    "    ax.imshow(data[0, :, :, i])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 0\n",
    "intermediate_output = intermediate_model.predict(tf.expand_dims(test_images[image_idx], 0))\n",
    "\n",
    "fig9 = plt.figure(figsize=(3, 3))\n",
    "fig9.set_facecolor('white')\n",
    "ax = fig9.add_subplot()\n",
    "ax.imshow(train_images[image_idx])\n",
    "ax.grid(False)\n",
    "\n",
    "for layer_idx in range(0, len(intermediate_output)):\n",
    "    data = intermediate_output[layer_idx]\n",
    "    fig = plt.figure(figsize=(16, math.ceil(data.shape[-1]/16)))\n",
    "    fig.set_facecolor('white')\n",
    "    for i in range(0, data.shape[-1]):\n",
    "        ax = fig.add_subplot(math.ceil(data.shape[-1]/16), 16, i+1)\n",
    "        ax.imshow(data[0, :, :, i])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
