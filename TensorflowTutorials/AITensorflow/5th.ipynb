{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5차시: 텐서플로우 2.x 활용 감성 분석 기초\n",
    "\n",
    "## AI 맛보기 5주차: 2020. 08. 04. 20:00 ~ 22:00 (120분)\n",
    "1. 도구 불러오기 및 버전 확인\n",
    "1. 학습 데이터 다운로드: 스탠포드 AI 연구실 - 영화 리뷰 DB\n",
    "1. 학습 데이터 살펴보기: 차원, 미리보기\n",
    "1. 학습 데이터 준비: 불러오기\n",
    "1. 학습 데이터 준비: 전처리\n",
    "1. 학습 데이터 준비: 전처리 결과 확인\n",
    "1. 워드 임베딩\n",
    "1. 학습 모델 정의 및 생성\n",
    "1. 학습\n",
    "1. 학습 결과 확인\n",
    "1. 예측: 가지고 놀기! \n",
    "\n",
    "#### 참고자료\n",
    "- [파이썬 3 표준 문서](https://docs.python.org/3/index.html)\n",
    "- [텐서플로우 텍스트 분류](https://www.tensorflow.org/tutorials/keras/text_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 도구 불러오기 및 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 준비\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import string\n",
    "\n",
    "import tensorflow as tf # 텐서플로우\n",
    "import matplotlib.pyplot as plt # 시각화 도구\n",
    "%matplotlib inline\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Tensorflow 버전을 확인합니다: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 학습 데이터 다운로드: (aclImdb) 영화 리뷰 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 다운로드\n",
    "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n",
    "                                  untar=True, cache_dir='.',\n",
    "                                  cache_subdir='')\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "print(f'데이터 압축 디렉터리 내부: {os.listdir(dataset_dir)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 구조 확인\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "print(f'학습 데이터 디렉터리 내부: {os.listdir(train_dir)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 학습 데이터 살펴보기: 미리보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정 학습 데이터 파일 확인\n",
    "pos_train_dir = os.path.join(train_dir, 'pos')\n",
    "pos_train_files = os.listdir(pos_train_dir)\n",
    "neg_train_dir = os.path.join(train_dir, 'neg')\n",
    "neg_train_files = os.listdir(neg_train_dir)\n",
    "print('긍정 파일: ', end='')\n",
    "for _ in range(0, 10):\n",
    "    print(random.choice(pos_train_files), end=' ')\n",
    "print()\n",
    "print('부정 파일: ', end='')\n",
    "for _ in range(0, 10):\n",
    "    print(random.choice(neg_train_files), end=' ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 내용 확인\n",
    "## https://translate.google.co.kr/\n",
    "## https://papago.naver.com/\n",
    "sample_file = os.path.join(train_dir, 'pos', '5667_10.txt')\n",
    "with open(sample_file, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 학습 데이터 준비: 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정리\n",
    "print('''학습을 위한 데이터는 이런 구조가 되어야 합니다.\n",
    "train/\n",
    "....pos/\n",
    "........file1.txt\n",
    "........file2.txt\n",
    "....neg/\n",
    "........file1.txt\n",
    "........file2.txt''')\n",
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "print(f'불필요한 데이터 파일을 정리합니다. {remove_dir}')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "seed = 20200804\n",
    "\n",
    "print('학습 데이터 세트를 불러옵니다.')\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        train_dir,\n",
    "        label_mode='binary',\n",
    "        batch_size=batch_size, \n",
    "        validation_split=validation_split, \n",
    "        subset='training',\n",
    "        seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 데이터 확인\n",
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(\"Review\", text_batch.numpy()[i])\n",
    "        print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('레이블 번호 - 이름 확인!')\n",
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('검증 데이터 세트를 불러옵니다.')\n",
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        train_dir, \n",
    "        label_mode='binary',\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split, \n",
    "        subset='validation', \n",
    "        seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 학습 데이터 준비: 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    stripped_html = tf.strings.regex_replace(stripped_html, \n",
    "                                             '(?:^|\\W)(?:the|a|an|be|was|am)(?:$|\\W)', '')\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                    '[%s]' % re.escape(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000\n",
    "sequence_length = 50\n",
    "\n",
    "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "        standardize=custom_standardization,\n",
    "        max_tokens=max_features,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('테스트 데이터와 레이블을 분리합니다.')\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('학습 완료 후 사용할 테스트 세트를 불러옵니다.')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        test_dir,\n",
    "        label_mode='binary',\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 학습 데이터 준비: 전처리 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('테스트 데이터를 확인합니다.')\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "print(\"Label\", raw_train_ds.class_names[int(first_label)])\n",
    "print(\"Vectorized review\", vectorize_text(tf.expand_dims(first_review, -1), first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각 특징 벡터의 원소 값을 확인할 수 있습니다.')\n",
    "voc_size = len(vectorize_layer.get_vocabulary())\n",
    "print(f'Vocabulary size: {voc_size}')\n",
    "base = 0\n",
    "cnt = 10\n",
    "if voc_size - cnt < base:\n",
    "    print(f'{voc_size-cnt} 보다는 작은 수를 입력해야 합니다.') \n",
    "else:\n",
    "    for i in range(base, base+cnt):\n",
    "        print(f'{i:4d} ---> {vectorize_layer.get_vocabulary()[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('학습, 검증, 테스트 데이터를 모두 벡터화 합니다.')\n",
    "vec_train_ds = raw_train_ds.map(vectorize_text)\n",
    "vec_val_ds = raw_val_ds.map(vectorize_text)\n",
    "vec_test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "print('데이터 입력부를 최적화합니다.')\n",
    "train_ds = vec_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = vec_val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = vec_test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 워드 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 4\n",
    "\n",
    "embedding_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(voc_size, embedding_dim),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "history = embedding_model.fit(\n",
    "        train_ds,\n",
    "        epochs=10,\n",
    "        validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for i, word in enumerate(vectorize_layer.get_vocabulary()[2:], start=2):\n",
    "    vec = embedding_model.layers[0].get_weights()[0][i] # skip 0, it's padding.\n",
    "    out_m.write(word + \"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "except ImportError:\n",
    "    pass\n",
    "else:\n",
    "    files.download('vecs.tsv')\n",
    "    files.download('meta.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 학습 모델 정의 및 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('모델을 정의합니다.')\n",
    "model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Embedding(voc_size, embedding_dim, mask_zero=True),\n",
    "                tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('모델을 준비합니다.')\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "              optimizer=tf.keras.optimizers.Adam(), \n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('모델 성능을 테스트합니다.')\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "fig1 = plt.figure(figsize=(6, 10))\n",
    "ax = fig1.add_subplot(2, 1, 1)\n",
    "ax.plot(epochs, loss, 'bo', label='Training loss')\n",
    "ax.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "ax.set_ylim((0, math.ceil(max(max(loss), max(val_loss)))))\n",
    "ax.set_title('Training and validation loss', fontsize=12)\n",
    "ax.set_xlabel('Epochs', fontsize=10)\n",
    "ax.set_ylabel('Loss', fontsize=10)\n",
    "ax.legend()\n",
    "\n",
    "ax = fig1.add_subplot(2, 1, 2)\n",
    "ax.plot(epochs, acc, 'bo', label='Training acc')\n",
    "ax.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "ax.set_ylim((0, math.ceil(max(max(acc), max(val_acc)))))\n",
    "ax.set_title('Training and validation accuracy', fontsize=12)\n",
    "ax.set_xlabel('Epochs', fontsize=10)\n",
    "ax.set_ylabel('Accuracy', fontsize=10)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. 예측: 가지고 놀기! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('모델 출력')\n",
    "export_model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    model,\n",
    "    tf.keras.layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
    ")\n",
    "\n",
    "loss, accuracy = export_model.evaluate(raw_test_ds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_str = input('테스트 입력: ').strip()\n",
    "# predicted = export_model.predict(tf.expand_dims(user_str, -1))[0][0]\n",
    "# print(f'예측 결과: {raw_train_ds.class_names[int(round(predicted))]} ({predicted:0.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. 모델 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#                 tf.keras.layers.Embedding(voc_size, embedding_dim, mask_zero=True),\n",
    "#                 tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "#                 tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "#                 tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                 tf.keras.layers.Dropout(0.5),\n",
    "#                 tf.keras.layers.Dense(1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
