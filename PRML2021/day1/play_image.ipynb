{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GPT on images\n",
    "\n",
    "Effectively re-implements OpenAI's [Image GPT](https://openai.com/blog/image-gpt/) model, getting GPT to model images instead of text, but using a near identical model. It's truly quite remarkable that a single model can agnostically do a great job modeling whatever data you give it: text, images, or whatever else. At the end of the day it is just a sequence of integers. Notice that unlike models like PixelCNN++ etc, this model knows nothing at all about the spatial layout of the pixels and has to learn the appropriate positional embeddings that reflect the spatial topology of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch helpfully makes it easy to download datasets, e.g. the common CIFAR-10 https://www.kaggle.com/c/cifar-10\n",
    "root = './'\n",
    "train_data = torchvision.datasets.CIFAR10(root, train=True, transform=None, target_transform=None, download=True)\n",
    "test_data  = torchvision.datasets.CIFAR10(root, train=False, transform=None, target_transform=None, download=True)\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are represented as array of size (height, width, 3), where is the RGB values, each is a uint8 in range 0..255. In CIFAR-10 for example, the height and width are both 32. \n",
    "\n",
    "**naive strategy**\n",
    "Now, to feed images into GPT we have to somehow turn every image into a sequence of integers. Since each image is 32\\*32\\*3 = 3072 uint8s, in principle we could just flatten each image out into a 3072-long sequence of numbers from 0..255 and train GPT on that. Note that we are free to feed this into GPT in any random arbitrary order, as long as the encoding order is fixed for all images. The problem with this is that GPT gets very expensive as you grow the sequence size, since each new predicted integer is a function of all previously predicted integers in the sequence, and the attention inside the Transformer modules gets very expensive.\n",
    "\n",
    "**k-means codebook strategy**\n",
    "Instead, the Image GPT strategy is to encode every individual RGB pixel into a codebook of 512 entries, which we train via the k-means clustering algorithm. This way, we only have a 32\\*32 = 1024-long sequence, but now of integers in the range 0..511. This is a net saving in compute because we're \"shrunk\" the sequence length by a factor of 3. On the other hand, our token encoding embedding parameters grow a bit in size, as well as the size of the Softmax classifier at the end.\n",
    "\n",
    "Okay let's train our codebook with k-means now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels\n",
    "pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(32*32, 3)[torch.randperm(32*32)[:5], :]\n",
    "px = torch.cat([pluck_rgb(x) for x, y in train_data], dim=0).float()\n",
    "print(px.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run kmeans to get our codebook\n",
    "\n",
    "def kmeans(x, ncluster, niter=10):\n",
    "    N, D = x.size()\n",
    "    c = x[torch.randperm(N)[:ncluster]] # init clusters at random\n",
    "    for i in range(niter):\n",
    "        # assign all pixels to the closest codebook element\n",
    "        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)\n",
    "        # move each codebook element to be the mean of the pixels that assigned to it\n",
    "        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])\n",
    "        # re-assign any poorly positioned codebook elements\n",
    "        nanix = torch.any(torch.isnan(c), dim=1)\n",
    "        ndead = nanix.sum().item()\n",
    "        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))\n",
    "        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters\n",
    "    return c\n",
    "\n",
    "ncluster = 512\n",
    "with torch.no_grad():\n",
    "    C = kmeans(px, ncluster, niter=8)\n",
    "\n",
    "print(C.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the training examples with our codebook to visualize how much we've lost in the discretization\n",
    "n_samples = 16\n",
    "ncol = 8\n",
    "nrow = n_samples // ncol + 1\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(n_samples):\n",
    "    \n",
    "    # encode and decode random data\n",
    "    x, y = train_data[np.random.randint(0, len(train_data))]\n",
    "    xpt = torch.from_numpy(np.array(x)).float().view(32*32, 3)\n",
    "    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1) # cluster assignments for each pixel\n",
    "    \n",
    "    # these images should look normal ideally\n",
    "    plt.subplot(nrow, ncol, i+1)\n",
    "    plt.imshow(C[ix].view(32, 32, 3).numpy().astype(np.uint8))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images above look relatively reasonable, so our 512-sized codebook is enough to reasonably re-represent RGB values. Ok cool. So now every image is just a 1024-long sequence of numbers between 0..511. Time to train a GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pt_dataset, clusters, perm=None):\n",
    "        self.pt_dataset = pt_dataset\n",
    "        self.clusters = clusters\n",
    "        self.perm = torch.arange(32*32) if perm is None else perm\n",
    "        \n",
    "        self.vocab_size = clusters.size(0)\n",
    "        self.block_size = 32*32 - 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pt_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.pt_dataset[idx]\n",
    "        x = torch.from_numpy(np.array(x)).view(-1, 3) # flatten out all pixels\n",
    "        x = x[self.perm].float() # reshuffle pixels with any fixed permutation and -> float\n",
    "        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1) # cluster assignments\n",
    "        return a[:-1], a[1:] # always just predict the next one in the sequence\n",
    "\n",
    "train_dataset = ImageDataset(train_data, C)\n",
    "test_dataset = ImageDataset(test_data, C)\n",
    "train_dataset[0][0] # one example image flattened out into integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For reference, **iGPT-S** from the paper is:\n",
    "- batch size of 128 and trained for 1M terations\n",
    "- Adam lr 0.003 with betas = (0.9, 0.95)\n",
    "- learning rate is warmed up for one epoch, then decays to 0\n",
    "- did not use weight decay or dropout\n",
    "- `n_layer=24, n_head=8, n_embd=512`\n",
    "\n",
    "We will do something similar but smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.model import GPT, GPTConfig, GPT1Config\n",
    "\n",
    "# we'll do something a bit smaller\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n",
    "                  embd_pdrop=0.0, resid_pdrop=0.0, attn_pdrop=0.0,\n",
    "                  n_layer=12, n_head=8, n_embd=256)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "\"\"\"\n",
    "Note that I am running on an 8-GPU V100 machine so each GPU has 32GB.\n",
    "If you don't have as many computational resources you have to bring down\n",
    "the batch_size until the model fits into your memory, and then you may\n",
    "also need to adjust the learning rate (e.g. decrease it a bit). Alternatively,\n",
    "you can use an even smaller model up above, bringing down the number of layers,\n",
    "number of heads, and the embedding size.\n",
    "\"\"\"\n",
    "\n",
    "tokens_per_epoch = len(train_data) * train_dataset.block_size\n",
    "train_epochs = 20 # todo run a bigger model and longer, this is tiny\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(max_epochs=train_epochs, batch_size=16*8, learning_rate=3e-3,\n",
    "                      betas = (0.9, 0.95), weight_decay=0,\n",
    "                      lr_decay=True, warmup_tokens=tokens_per_epoch, final_tokens=train_epochs*tokens_per_epoch,\n",
    "                      ckpt_path='cifar10_model.pt',\n",
    "                      num_workers=8)\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the state of the best model we've seen based on early stopping\n",
    "checkpoint = torch.load('cifar10_model.pt')\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to sample we also have to technically \"train\" a separate model for the first token in the sequence\n",
    "# we are going to do so below simply by calculating and normalizing the histogram of the first token\n",
    "counts = torch.ones(ncluster) # start counts as 1 not zero, this is called \"smoothing\"\n",
    "rp = torch.randperm(len(train_dataset))\n",
    "nest = 5000 # how many images to use for the estimation\n",
    "for i in range(nest):\n",
    "    a, _ = train_dataset[int(rp[i])]\n",
    "    t = a[0].item() # index of first token in the sequence\n",
    "    counts[t] += 1\n",
    "prob = counts/counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from mingpt.utils import sample\n",
    "\n",
    "n_samples = 32\n",
    "start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob)\n",
    "start_pixel = torch.from_numpy(start_pixel).to(trainer.device)\n",
    "pixels = sample(model, start_pixel, 32*32-1, temperature=1.0, sample=True, top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualization we have to invert the permutation used to produce the pixels\n",
    "iperm = torch.argsort(train_dataset.perm)\n",
    "\n",
    "ncol = 8\n",
    "nrow = n_samples // ncol\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i in range(n_samples):\n",
    "    pxi = pixels[i][iperm] # note: undo the encoding permutation\n",
    "    \n",
    "    plt.subplot(nrow, ncol, i+1)\n",
    "    plt.imshow(C[pxi].view(32, 32, 3).numpy().astype(np.uint8))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some of the learned positional embeddings, maybe they contain structure\n",
    "plt.figure(figsize=(5, 5))\n",
    "nsee = 8*8\n",
    "ncol = 8\n",
    "nrow = nsee // ncol\n",
    "for i in range(nsee):\n",
    "    \n",
    "    ci = model.pos_emb.data[0, :, i].cpu()\n",
    "    zci = torch.cat((torch.tensor([0.0]), ci)) # pre-cat a zero\n",
    "    rzci = zci[iperm] # undo the permutation to recover the pixel space of the image\n",
    "    \n",
    "    plt.subplot(nrow, ncol, i+1)\n",
    "    plt.imshow(rzci.view(32, 32).numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# huh, pretty cool! :P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
